download.file(file.url1, destfile="edu.csv")
gdp<-read.csv("gdp.csv",header=T, skip = 4, sep=",", dec=",",colClasses="character")
gdp<-gdp[1:190,c(1,4,5)]
gdp<-data.frame(gdp)
makenumeric<-as.numeric(gsub(",","",gdp[,3]))
View(gdp)
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
nrow(sortmergedData_dec)
rank<-c(1:189)
HI<-cbind(sortmergedData_dec,rank)
HI<-subset(HI, Income.Group=="High income: OECD"|Income.Group=="High income: nonOECD")
Hisub<-HI[,c(1,4,6,35)]
sapply(split(Hisub[,4],Hisub$Income.Group),mean)
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
nrow(sortmergedData_dec)
rank<-c(1:189)
HI<-cbind(sortmergedData_dec,rank)
HI<-subset(HI, Income.Group=="High income: OECD"|Income.Group=="High income: nonOECD")
Hisub<-HI[,c(1,4,6,35)]
sapply(split(Hisub[,4],Hisub$Income.Group),mean)
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
install.packages("Rcpp")
install.packages("plyr")
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
count(Q5,"Income.Group")
install.packages("Rcpp")
install.packages("plyr")
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
count(Q5,"Income.Group")
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
count(Q5,"Income.Group")
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
count(Q5,"Income.Group")
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
nrow(sortmergedData_dec)
rank<-c(1:189)
HI<-cbind(sortmergedData_dec,rank)
HI<-subset(HI, Income.Group=="High income: OECD"|Income.Group=="High income: nonOECD")
Hisub<-HI[,c(1,4,6,35)]
sapply(split(Hisub[,4],Hisub$Income.Group),mean)
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
nrow(sortmergedData_dec)
rank<-c(1:189)
HI<-cbind(sortmergedData_dec,rank)
HI<-subset(HI, Income.Group=="High income: OECD"|Income.Group=="High income: nonOECD")
Hisub<-HI[,c(1,4,6,35)]
sapply(split(Hisub[,4],Hisub$Income.Group),mean)
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
count(Q5,"Income.Group")
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
count(Q5,"Income.Group")
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
library(Rcpp)
library(plyr)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
count(Q5,"Income.Group")
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
Q5<-sortmergedData_dec[1:38,c(1,4,6)]
sortmergedData_dec<-mergedData[order(mergedData[,4],decreasing=TRUE),]
quatile<-c(0.2,0.4,0.6,0.8,1)
qsep<-quantile(sortmergedData_dec$makenumeric,quatile)
sep<-sortmergedData_dec$makenumeric
xtabs(sep~sortmergedData$Income.Group)
Q5<-sep[1:38,c(1,4,6)]
count(Q5,"Income.Group")
income_group <- group_by(q3_merge, Income.Group)
summarise(income_group, avg = mean(Ranking, na.rm = TRUE))
# Question 5
# cut Ranking into 5 quantile groups
q3_merge$RankingGroup <- cut(q3_merge$Ranking, breaks = 5)
# make a table vs Income.Group
table(q3_merge$RankingGroup, q3_merge$Income.Group)
# download file from server
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",
destfile = "q3_1.csv",
method = "curl")
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",
destfile = "q3_2.csv",
method = "curl")
# load the datasets
q3_1 <- read.csv("q3_1.csv", header = TRUE, skip = 3, sep = ",")
q3_2 <- read.csv("q3_2.csv", header = TRUE)
# reshaping data
q3_1 <- q3_1[2:191, c(1,2,4,5)]
rownames(q3_1) <- NULL
q3_1 <- rename(q3_1, CountryCode = X)
# merge two datasets
q3_merge <- join(q3_1, q3_2)
# show the number of matches
sum(!is.na(unique(q3_merge$Ranking)))
# convert the data type of Ranking
q3_merge$Ranking <- as.numeric(as.character(q3_merge$Ranking))
# show the 13th country after sort decending
q3_merge <- arrange(q3_merge, desc(Ranking))
q3_merge[13,3]
# Question 4
# Group q3_merge by Income.Group
income_group <- group_by(q3_merge, Income.Group)
summarise(income_group, avg = mean(Ranking, na.rm = TRUE))
# Question 5
# cut Ranking into 5 quantile groups
q3_merge$RankingGroup <- cut(q3_merge$Ranking, breaks = 5)
# make a table vs Income.Group
table(q3_merge$RankingGroup, q3_merge$Income.Group)
newgdp<-cbind(gdp,makenumeric)
edu<-read.csv("edu.csv", header=TRUE)
mergedData<-merge(newgdp,edu,by.x="X",by.y="CountryCode")
sortmergedData<-mergedData[order(mergedData[,4],decreasing=FALSE),]
nrow(mergedData)
sortmergedData[13,c(1,5)]
View(newgdp)
?tempfile
?file
?tempfile
?file
temp <- file()
temp <- tempfile()
data <- "C:\Users\teistertp\Documents\Coursera\gettingcleaningdata\data"
data <- "~\data"
data <- ".\data"
data <- "\data"
temp <- tempfile()
download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp)
unzip(data, list = TRUE) #This provides the list of variables and I choose the ones that are applicable for this data set
YTest <- read.table(unzip(temp, "UCI HAR Dataset/test/y_test.txt"))
XTest <- read.table(unzip(temp, "UCI HAR Dataset/test/X_test.txt"))
SubjectTest <- read.table(unzip(temp, "UCI HAR Dataset/test/subject_test.txt"))
YTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/y_train.txt"))
XTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/X_train.txt"))
SubjectTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/subject_train.txt"))
Features <- read.table(unzip(temp, "UCI HAR Dataset/features.txt"))
unlink(temp) # very important to remove this
unzip(temp, list = TRUE) #This provides the list of variables and I choose the ones that are applicable for this data set
YTest <- read.table(unzip(temp, "UCI HAR Dataset/test/y_test.txt"))
XTest <- read.table(unzip(temp, "UCI HAR Dataset/test/X_test.txt"))
SubjectTest <- read.table(unzip(temp, "UCI HAR Dataset/test/subject_test.txt"))
YTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/y_train.txt"))
XTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/X_train.txt"))
SubjectTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/subject_train.txt"))
Features <- read.table(unzip(temp, "UCI HAR Dataset/features.txt"))
unlink(temp) # very important to remove this
temp <- tempfile()
download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",temp)
unzip(temp, list = TRUE) #This provides the list of variables and I choose the ones that are applicable for this data set
YTest <- read.table(unzip(temp, "UCI HAR Dataset/test/y_test.txt"))
XTest <- read.table(unzip(temp, "UCI HAR Dataset/test/X_test.txt"))
SubjectTest <- read.table(unzip(temp, "UCI HAR Dataset/test/subject_test.txt"))
YTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/y_train.txt"))
XTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/X_train.txt"))
SubjectTrain <- read.table(unzip(temp, "UCI HAR Dataset/train/subject_train.txt"))
Features <- read.table(unzip(temp, "UCI HAR Dataset/features.txt"))
unlink(temp) # very important to remove this
colnames(XTrain) <- t(Features[2])
colnames(XTest) <- t(Features[2])
?temp
#download zip file into temporary folder and begin to unzip the files.
file <- tempfile()
download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",file)
unzip(file, list = TRUE) #This provides the list of variables and I choose the ones that are applicable for this data set
Y_Test <- read.table(unzip(file, "UCI HAR Dataset/test/y_test.txt"))
X_Test <- read.table(unzip(file, "UCI HAR Dataset/test/X_test.txt"))
Subject_Test <- read.table(unzip(file, "UCI HAR Dataset/test/subject_test.txt"))
Y_Train <- read.table(unzip(file, "UCI HAR Dataset/train/y_train.txt"))
X_Train <- read.table(unzip(file, "UCI HAR Dataset/train/X_train.txt"))
Subject_Train <- read.table(unzip(file, "UCI HAR Dataset/train/subject_train.txt"))
Features <- read.table(unzip(file, "UCI HAR Dataset/features.txt"))
unlink(file)
colnames(X_Train) <- t(Features[2])
colnames(X_Test) <- t(Features[2])
#merging
X_Train$activities <- Y_Train[, 1]
X_Train$participants <- Subject_Train[, 1]
X_Test$activities <- Y_Test[, 1]
X_Test$participants <- Subject_Test[, 1]
?master
#merging training and test to create one data set
data <- rbind(X_Train, X_Test)
duplicated(colnames(data))
data <- data[, !duplicated(colnames(data))]
Mean <- grep("mean()", names(data), value = FALSE, fixed = TRUE)
Mean <- append(Mean, 471:477)
MeanMatrix <- data[Mean]
#standard deviation
STD <- grep("std()", names(data), value = FALSE)
DevMatrix <- data[STD]
data$activities <- as.character(data$activities)
data$activities[data$activities == 1] <- "Walking"
data$activities[data$activities == 2] <- "Walking Upstairs"
data$activities[data$activities == 3] <- "Walking Downstairs"
data$activities[data$activities == 4] <- "Sitting"
data$activities[data$activities == 5] <- "Standing"
data$activities[data$activities == 6] <- "Laying"
data$activities <- as.factor(data$activities)
names(data)  # survey the data
names(data) <- gsub("Acc", "Accelerator", names(data))
names(data) <- gsub("Mag", "Magnitude", names(data))
names(data) <- gsub("Gyro", "Gyroscope", names(data))
names(data) <- gsub("^t", "time", names(data))
names(data) <- gsub("^f", "frequency", names(data))
data$participants <- as.character(data$participants)
data$participants[data$participants == 1] <- "Participant 1"
data$participants[data$participants == 2] <- "Participant 2"
data$participants[data$participants == 3] <- "Participant 3"
data$participants[data$participants == 4] <- "Participant 4"
data$participants[data$participants == 5] <- "Participant 5"
data$participants[data$participants == 6] <- "Participant 6"
data$participants[data$participants == 7] <- "Participant 7"
data$participants[data$participants == 8] <- "Participant 8"
data$participants[data$participants == 9] <- "Participant 9"
data$participants[data$participants == 10] <- "Participant 10"
data$participants[data$participants == 11] <- "Participant 11"
data$participants[data$participants == 12] <- "Participant 12"
data$participants[data$participants == 13] <- "Participant 13"
data$participants[data$participants == 14] <- "Participant 14"
data$participants[data$participants == 15] <- "Participant 15"
data$participants[data$participants == 16] <- "Participant 16"
data$participants[data$participants == 17] <- "Participant 17"
data$participants[data$participants == 18] <- "Participant 18"
data$participants[data$participants == 19] <- "Participant 19"
data$participants[data$participants == 20] <- "Participant 20"
data$participants[data$participants == 21] <- "Participant 21"
data$participants[data$participants == 22] <- "Participant 22"
data$participants[data$participants == 23] <- "Participant 23"
data$participants[data$participants == 24] <- "Participant 24"
data$participants[data$participants == 25] <- "Participant 25"
data$participants[data$participants == 26] <- "Participant 26"
data$participants[data$participants == 27] <- "Participant 27"
data$participants[data$participants == 28] <- "Participant 28"
data$participants[data$participants == 29] <- "Participant 29"
data$participants[data$participants == 30] <- "Participant 30"
data$participants <- as.factor(data$participants)
data.dt <- data.table(data)
#This takes the mean of every column broken down by participants and activities
TidyData <- data.dt[, lapply(.SD, mean), by = 'participants,activities']
write.table(TidyData, file = "Tidy.txt", row.names = FALSE)
library(data.table)
data.dt <- data.table(data)
#This takes the mean of every column broken down by participants and activities
TidyData <- data.dt[, lapply(.SD, mean), by = 'participants,activities']
write.table(TidyData, file = "Tidy.txt", row.names = FALSE)
?write.table
#download zip file into temporary folder and begin to unzip the files.
file <- tempfile()
download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",file)
unzip(file, list = TRUE) #This provides the list of variables and I choose the ones that are applicable for this data set
Y_Test <- read.table(unzip(file, "UCI HAR Dataset/test/y_test.txt"))
X_Test <- read.table(unzip(file, "UCI HAR Dataset/test/X_test.txt"))
Subject_Test <- read.table(unzip(file, "UCI HAR Dataset/test/subject_test.txt"))
Y_Train <- read.table(unzip(file, "UCI HAR Dataset/train/y_train.txt"))
X_Train <- read.table(unzip(file, "UCI HAR Dataset/train/X_train.txt"))
Subject_Train <- read.table(unzip(file, "UCI HAR Dataset/train/subject_train.txt"))
Features <- read.table(unzip(file, "UCI HAR Dataset/features.txt"))
unlink(file)
#column names
colnames(X_Train) <- t(Features[2])
colnames(X_Test) <- t(Features[2])
#merging
X_Train$activities <- Y_Train[, 1]
X_Train$candidates <- Subject_Train[, 1]
X_Test$activities <- Y_Test[, 1]
X_Test$candidates <- Subject_Test[, 1]
#merging training and test to create one data set
data <- rbind(X_Train, X_Test)
duplicated(colnames(data))
data <- data[, !duplicated(colnames(data))]
#mean
Mean <- grep("mean()", names(data), value = FALSE, fixed = TRUE)
Mean <- append(Mean, 471:477)
MeanMatrix <- data[Mean]
#standard deviation
STD <- grep("std()", names(data), value = FALSE)
DevMatrix <- data[STD]
data$activities <- as.character(data$activities)
data$activities[data$activities == 1] <- "Walking"
data$activities[data$activities == 2] <- "Walking Upstairs"
data$activities[data$activities == 3] <- "Walking Downstairs"
data$activities[data$activities == 4] <- "Sitting"
data$activities[data$activities == 5] <- "Standing"
data$activities[data$activities == 6] <- "Laying"
data$activities <- as.factor(data$activities)
names(data)  # survey the data
names(data) <- gsub("Acc", "Accelerator", names(data))
names(data) <- gsub("Mag", "Magnitude", names(data))
names(data) <- gsub("Gyro", "Gyroscope", names(data))
names(data) <- gsub("^t", "time", names(data))
names(data) <- gsub("^f", "frequency", names(data))
data$candidates <- as.character(data$candidates)
data$candidates[data$candidates == 1] <- "Candidate 1"
data$candidates[data$candidates == 2] <- "Candidate 2"
data$candidates[data$candidates == 3] <- "Candidate 3"
data$candidates[data$candidates == 4] <- "Candidate 4"
data$candidates[data$candidates == 5] <- "Candidate 5"
data$candidates[data$candidates == 6] <- "Candidate 6"
data$candidates[data$candidates == 7] <- "Candidate 7"
data$candidates[data$candidates == 8] <- "Candidate 8"
data$candidates[data$candidates == 9] <- "Candidate 9"
data$candidates[data$candidates == 10] <- "Candidate 10"
data$candidates[data$candidates == 11] <- "Candidate 11"
data$candidates[data$candidates == 12] <- "Candidate 12"
data$candidates[data$candidates == 13] <- "Candidate 13"
data$candidates[data$candidates == 14] <- "Candidate 14"
data$candidates[data$candidates == 15] <- "Candidate 15"
data$candidates[data$candidates == 16] <- "Candidate 16"
data$candidates[data$candidates == 17] <- "Candidate 17"
data$candidates[data$candidates == 18] <- "Candidate 18"
data$candidates[data$candidates == 19] <- "Candidate 19"
data$candidates[data$candidates == 20] <- "Candidate 20"
data$candidates[data$candidates == 21] <- "Candidate 21"
data$candidates[data$candidates == 22] <- "Candidate 22"
data$candidates[data$candidates == 23] <- "Candidate 23"
data$candidates[data$candidates == 24] <- "Candidate 24"
data$candidates[data$candidates == 25] <- "Candidate 25"
data$candidates[data$candidates == 26] <- "Candidate 26"
data$candidates[data$candidates == 27] <- "Candidate 27"
data$candidates[data$candidates == 28] <- "Candidate 28"
data$candidates[data$candidates == 29] <- "Candidate 29"
data$candidates[data$candidates == 30] <- "Candidate 30"
data$candidates <- as.factor(data$candidates)
library(data.table)
data.dt <- data.table(data)
#This takes the mean of every column broken down by candidates and activities
TidyData <- data.dt[, lapply(.SD, mean), by = 'candidates,activities']
write.table(TidyData, file = "Tidy.txt", row.names = FALSE)
View(TidyData)
View(Features)
setwd("~/Coursera/exploratory data analysis/ExData_Plotting2")
require(downloader)
install.packages("downloader")
require(downloader)
library(downloader)
library(downloader)
file <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
download(file, dest = "EPAdata.zip", mode= "wb")
unzip("EPAdata.zip")
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classificaiton_Code.rds")
df <- with(NEI, aggregate(Emissions, by = list(year), sum))
#Data load
library(downloader)
file <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
download(file, dest = "EPAdata.zip", mode= "wb")
unzip("EPAdata.zip")
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
df <- with(NEI, aggregate(Emissions, by = list(year), sum))
plot(df, type = "o", main = "Total PM2.5 Emissions", xlab = "Year", ylab = "PM2.5 Emissions", pch = 19, col = "darkred", lty = 6)
plot(df, type = "1", main = "Total PM2.5 Emissions", xlab = "Year", ylab = "PM2.5 Emissions", pch = 19, col = "darkred", lty = 6)
plot(df, type = "l", main = "Total PM2.5 Emissions", xlab = "Year", ylab = "PM2.5 Emissions", pch = 19, col = "darkred", lty = 6)
plot(df, type = "o", main = "Total PM2.5 Emissions", xlab = "Year", ylab = "PM2.5 Emissions", pch = 19, col = "darkred", lty = 6)
plot(df, type = "o", main = "PM2.5 Emissions", xlab = "Year", ylab = "PM2.5 Emissions", pch = 19, col = "darkred", lty = 6)
png("plot1.png")
plot(df, type = "o", main = "PM2.5 Emissions", xlab = "Year", ylab = "PM2.5 Emissions", pch = 19, col = "darkred", lty = 6)
dev.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darblue", lty = 5)
dev.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "b", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off()
dev.cur()
dev.off(1)
dev.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off(2)
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off(1)
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off(2)
dev.off(3)
dev.off(0)
dev.cur()
dev.cur(1)
?dev.contorl
library(utils)
dev.off(0)
dev.off()
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "o", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "b", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "b", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
graphics.off()
png("plot2.png")
sub1 <- subset(NEI, fips == "24510")
balt <- tapply(sub1$Emissions, sub1$year, sum)
plot(balt, type = "b", main = "PM2.5 Emissions in Baltimore County", xlab = "Year", ylab = "PM2.5 Emissions", pch = 18, col = "darkblue", lty = 5)
dev.off()
png("plot3.png")
library(ggplot2)
sub2 <- subset(NEI, fips = "24510")
balt.sources <- aggregate(sub2[c("Emissions")], list(type = sub2$type, year = sub2$year), sum)
qplot(year, Emissions, data = balt.sources, color = type, geom = "line") + ggtitle("PM2.5 Emissions in Baltimore County by Source") + xlab("Year") + ylab("PM2.5 Emissions")
dev.off()
#3. Of the four types of sources indicated by the type (point, nonpoint, onroad, nonroad) variable, which of these four sources have seen decreases in emissions from 1999–2008 for Baltimore City? Which have seen increases in emissions from 1999–2008? Use the ggplot2 plotting system to make a plot answer this question.
png("plot3.png")
library(ggplot2)
sub2 <- subset(NEI, fips = "24510")
balt.sources <- aggregate(sub2[c("Emissions")], list(type = sub2$type, year = sub2$year), sum)
qplot(year, Emissions, data = balt.sources, color = type, geom = "line") + ggtitle("PM2.5 Emissions in Baltimore County by Source") + xlab("Year") + ylab("PM2.5 Emissions")
dev.off()
